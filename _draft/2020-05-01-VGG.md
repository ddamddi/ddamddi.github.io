---
layout: post
title: "[Paper] VGG 16/19"
description: ""
modified: 2020-05-01
categories: study
tags: paper
comments: true
---

>

VGG

### 2.1 Architecture
- Input 이미지 사이즈는 224x224x3(RGB)로 fixed
- Input Image Pre-processing은 딱 한 가지 -> traing set의 RGB mean value를 pixel-wise로 subtract

- Conv layer의 Receptive field size는 3x3로 고정(1x1도 사용하긴함. for liner transformation of the input channel)
- Conv Stride는 1 pixel fixed
- Conv layer이후에 spatial resolution은 유지(padding 사용)
- Spatial pooling은 5번의 Max-pooling을 사용(224x224 -> 7x7)
- Max-pooling은 2x2 pixel window, stride 2

- Conv layers stack 이후 3개의 FC(Fully-Connected) layer (모든 depth에서 동일)
- 2개는 4096 channel, 마지막 1개는 ImageNet class 갯수(1000)와 동일
- 마지막 layer는 softmax layer

- 

### 2.2 Configuration
- conv layer의 channel 갯수는 64부터 시작해서 max-pooling 이후 2배로 증가해서 최대 512 channel 까지 증가

- depth가 깊어지는 것에 비해서 weight의 개수가 적게 증가


### 2.3 discussion
- 하나의 7x7 Conv layer 대신에 3개의 3x3 Conv layer 사용(또는 하나의 5x5 Conv layer 대신 2개의 3x3 Conv layer 사용)
1. 여러번의 Non-linear ReLU layer -> decision function be more distinctive
2. Parameter 수의 감소
    - e.g. 하나의 7x7 Conv layer의 Weight = 1x7x7xC<sup>2</sup> = 49C<sup>2</sup> weights
    - e.g. 세 개의 3x3 Conv layer의 Weight = 3x3x3xC<sup>2</sup> = 27C<sup>2</sup> weights
    - Weight Parameter의 감소효과  

3. 